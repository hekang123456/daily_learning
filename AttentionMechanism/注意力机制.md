---
title: Attention Mechanism
categories: Deep Learning
tags: [Attention Mechanism, 注意力机制， self-attention]
date: 2019-03-14
---

### 注意力机制

####  （一）. 一般的注意力机制的公式

$$
\begin{align}
S^{l \times 1} &= \tanh (H^{l \times m} W^{m \times n} +b^{n})U^{n \times 1} \\
\alpha^{l \times 1} &= \frac{ \exp (S^{l \times 1}) }{ \sum\limits_{i=1}^{l} \exp （S_{i,1}^{l \times 1}）} \\
v &= \sum\limits_{i=1}^l \alpha_{i, 1} H^{l \times m}_{i，：} 
\end{align}
$$

> 在上面的公式中 上标表示的是符号对应的矩阵的形状， 下标指的是取这个矩阵中的具体某一个元素， 冒号表示选取那个维度的所有元素。 

- 第一个公式表示的是打分函数的计算， 原始的输入 $H^{L \times m}$ 表示为 $l \times m $ 的一个矩阵。 例如有 $l$ 个词的文本，每个文本的词嵌入是 $m$ 维； 每个时间步 RNN 的输出的合并，$l$ 表示时间步的长度， $m$ 表示每个时间步输入向量的维度。  首先将 $H$ 经过一个 全连接层 (dense layer ， 就是两个矩阵相乘)  将 $m$ 维的向量变换为 $n$ 维的向量。再经过一个激活函数， 然后再经过一个全连接层。 得到$S^{l \times 1}$ ，称为是对每个输入特征向量的打分。 类似的打分函数还有：
  $$
  \begin{align}
  S^{l \times 1} &= H^{l \times m}U^{m \times 1} \\
  S^{l \times 1} &= H^{l \times m}W^{m \times n} U^{n \times 1} \\
  S^{l \times 1} &= \tanh (H^{l \times m }) U^{m \times 1}  
  \end{align}
  $$
  简单一点理解就是将 输入 $H^{l \times m}$ 通过矩阵运算得到一个 $S^{l \times 1}$ 的矩阵， 这个矩阵中的每个值代表了对应位置特征向量的重要程度。  公式中的$W, b, U$ 都是权重，在注意力网络中通过随机初始化，然后通过反向传播进行训练的。

- 第二个公式表示的是一个 Softmax 函数。 将得到的 $S^{l \times 1}$ 看做一个向量， 那么这就是对这个向量的归一化的过程。

- 第三个公式表示根据第二步确定的每个特征向量的重要程度，对原始输入 $H$ 中的特征向量进行加权求和。 

- 举个例子：

  -  输入 $H = [[1,2,3], [2,2,2], [1,1,1], [2,1,2]]$  ，$W, b, U$ 分别初始化为 $W = [[1,1], [2,2], [1,2]]， b=[[1, 1]], U=[[2], [1]]$

  - code

    ```python
    import numpy as np
    H = np.array([[1,2,3], [2,2,2], [1,1,1], [2,1,2]])
    W = np.array([[1,1], [2,2], [1,2]])
    b = np.array([[1, 1]])
    U = np.array([[2], [1]])
    
    S = np.dot(np.dot(H, W)+b, U)
    alpha = np.exp(S)/sum(np.exp(S))
    res = np.dot(np.array([[1,1,1,1]]), H* alpha)
    ```

#### (二). seq2seq 中的 Attention

- 先写一遍 LSTM 的计算公式
  $$
  \begin{align}
  \left[
  \begin{array}
  i_t \\ f_t \\o_t \\ \hat{C_t}
  \end{array}
  \right] &= 
  \left[
  \begin{array}
  \\ \sigma \\ \sigma \\ \sigma  \\ \tanh
  \end{array} 
  \right]
  (W \cdot [h_{t-1}, x_t] + b) \\
  C_t &= f_t* C_{t-1} +  i_t * \hat{C_t} \\
  h_t &= o_t * C_t
  \end{align}
  $$
  
  GRU 的公式就不写了，也差不多都是类似的结构。

- 一般的 seq2seq 结构是

  <img src=AttentionMechanismInDeepLearning/rnn_encoder_decoder.png width=500 />

$$
\begin{align} 
\text{Source} &= <x_1, x_2, ..., x_m> \\  
\text{Target} &= <y_1, y_2, ..., y_n> \\
C  &= F(x_1, x_2, ..., x_m) \\
y_i &= \mathcal{G} (\mathbf{C}, y_1, y_2, ..., y_{i-1})  
\end{align}
$$

- 引入了注意力机制的结构是

  <img src=AttentionMechanismInDeepLearning/encoder_decoder_attention.png width=500/>

$$
\begin{align}
y_i &= \mathcal{G} (\mathbf{C_i} , y_1, y_2, ..., y_{i-1}) \\
C_i &= \sum_{j=1}^{L_x} a_{ij} h_j
\end{align}
$$

- 自己的理解

  引入了注意力结构的 seq2seq 结构中加入了 $C_i$，  这里的 $C_i$ 是注意力机制中最后得到的向量， 对应与 (一) 中的 $v$ 。 因此解码端的序列长度为多少就重复了多少次 (一) 中的注意力。 每个 $C_i$ 一般会和 LSTM（或者其它的RNN） 中的隐状态 $C_t$ 进行相加或者拼接。 而没有引入注意力的 seq2seq 只有编码端最后时刻的隐状态一个。

#### (三) . Attention 更加普遍的定义

$$
Attention(Q, K, V) = softmax(\frac{QK^T}{ \sqrt{d_k} }) V
$$

​	这个定义来源于  [Attention is All You Need](<https://arxiv.org/pdf/1706.03762.pdf>) 这篇论文。 $V$ 指的是 Values, 也就是所有的特征的集合，例如对于RNN 中，我们的目标是关注所有的 RNN 的输出，那么$V$ 的第 $i$ 行表示第 $i$ 时刻的输出。我们假设每一个 value 都一个键与之对应。这个 $key$ 值是用来确定对应的 $value$ 的一组值， 也就是说我们能够通过 $key$ 来找出对应的 $value$ 值是多少。 同时我们需要通过 $key$ 值来确定对应的 $value$ 在文本中的重要程度。  我们需要通过一个 query 来查询对应 $key$ 值的 $value$ 的重要程度。 因此在公式中 $Q$ 表示的是一组  $query$ 的集合， 矩阵中的一行代表的是一条查询。 $QK^T$ 表示矩阵乘法， 那么我们得到的任意一个行向量来自于 对应的一个 query 与所有 $K$ 中的行向量做点乘(注意，这里是 $K$ 中的行向量，对应于 $K^T$ 中的列向量)。$softmax $ 表示对这个行向量做归一化处理。 $\sqrt{d_k}$  表示的是对相应的值缩小。最后和 $V$ 做矩阵相乘得到的结果中任意一行的结果表示的是一条查询对应的注意力得到的结果。 

​	当 $key$ 和 $value$ 都是一样的时候， 并且打分函数是 $H^{l \times m}U^{m \times 1}$ 的情况下，这个定义其实和 $(一)$ 中的内容是一样的。 只是每一条 query 对应着 $(一)$ 中的一次操作。

​	这里的 $K$ 和 $V$ 可以不一样，但是在大部分情况下都是一样的。



#### (四). Self-Attention

​	在 $(一)$ 中的表示方法中 $K$ 和 $V$ 都是原始的输入 即 $H$ ,  $Q$ 对应着 $W$ 。  当 $K=V= Q$ 的时候，我们认为这是一种自注意力， 也就是$Q$ 中的一条查询和对应 $K$ 中的一条值进行点积， 这个点积的含义就是通过自身与自身的比较，来确定自身的重要程度。 