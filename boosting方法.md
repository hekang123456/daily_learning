---
title: 提升方法 
categories: ML
tags: [AdaBoost, GBDT, 提升树, 前向分布算法]
date: 2019-01-05
---

# 提升方法 

#### 介绍

- 强可学习与弱可学习
  - 强可学习 : 一个概念（类）,存在一个多项式的学习算法能够学习他，并且正确率很高，则这个概念是强可学习的。
  - 弱可学习：一个概念（类）,存在一个多项式的学习算法能够学习他，但是学习的正确率只比随机猜测略好，那么这个概念就是弱可学习的。
  - 强可学习和弱可学习是等价的， 一个概念是强可学习的充分必要条件是这个概念是弱可学习的。

- 提升方法的由来

  在学习中， 如果发现了 "弱学习算法" 那么能够将它提升为 "强学习算法"。

- 提升方法的两个问题
  - 在每一轮如何改变训练数据的权重值或概率分布。
  - 如何将弱分类器合成一个强分类器。

#### AdaBoost

​	AdaBoost 通过在每次训练过程中根据当前分类器对数据分类是否正确，调整训练数据的权重值。 通过当前分类器在训练数据集上的分类精度判断当前分类器的权重，最后将所有分类器进行加权求和得到最终的分类器。

- AdaBoost 的计算流程

  